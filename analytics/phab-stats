#!/usr/bin/env python

# This script generates a set of productivity related metrics for a given
# Phabricator workboard and time range. The Phabricator workboard details
# must be specified via config file (see phab-stats-config.json). The time
# range is specified via start_date and end_date parameters.
#
# IMPORTANT: The script assumes that resolved tasks stay in the workboard
# 'forever'. This way, it can get the workboard via http, parse it and get
# all tasks that some day travelled through it.


import os
import re
import argparse
import json
import phabricator
import requests
from datetime import datetime, timedelta

DATE_FORMAT = '%Y-%m-%d'

def parse_arguments():
    parser = argparse.ArgumentParser(
        description='Generate metrics on Phabricator workboard ' +
                    'activity for a given date range.')
    def date_type(date_str):
        return datetime.strptime(date_str, DATE_FORMAT)
    parser.add_argument('start_date',
        help='Start of the interval for the generated summary (YYYY-MM-DD).',
        type=date_type)
    parser.add_argument('end_date',
        help='End of the interval for the generated summary (YYYY-MM-DD).',
        type=date_type)
    this_file_dir = os.path.dirname(os.path.realpath(__file__))
    parser.add_argument('--config',
        help='Location of the config file. Default: phab-stats-config.json.',
        default=os.path.join(this_file_dir, 'phab-stats-config.json'))
    parser.add_argument('--html',
        action='store_true',
        help='Generate HTML file instead of outputting to standard out.')
    parser.add_argument('--open',
        action='store_true',
        help='If using --html, open the html file after generating.')
    parser.add_argument('--html-file',
        default='output.html',
        help='Output HTML file name. Default: output.html')
    return parser.parse_args()


def get_config(args):
    with open(args.config, 'r') as config_file:
        config = json.loads(config_file.read())
        # A map from column names to column values (scores).
        # Necessary to compute some metrics.
        config['column_values'] = {c['name']: c['value'] for c in config['columns']}
        # A map from column phab-ids to column names.
        # Necessary to understand Phabricator api response.
        config['column_names'] = {c['phid']: c['name'] for c in config['columns']}
    return config


class Task(object):
    """
    This class represents a Phabricator task.
    It also groups some convenient methods on task transactions.
    Phabricator stores any task update as a transaction. So, parsing
    a list of task transactions, lots of information can be extracted.
    """

    def __init__(self, id, name):
        self.id = id
        self.name = name
        # The transaction list is asigned separately for performance reasons.
        self.transactions = None
        # The following fields depend on the transactions to be calculated.
        self.column = None
        self.cached_start_date = None
        self.cached_resolved_date = None
        self.cached_created_date = None
        self.is_resolved = None
        self.is_closed = None

    def set_transactions(self, transactions):
        """
        Sets the task's transactions and triggers the
        calculation of the fields that depend on them.
        """
        self.transactions = transactions
        self.column = self.column_at('now')

        # force is_resolved to get set
        self.resolved_date() # TODO find a cleaner way to do this
        self.update_is_closed()

    def update_is_closed(self):
        for transaction in self.transactions:
            if (transaction['transactionType'] == 'status' and
                    (transaction['newValue'] == 'invalid' or
                    transaction['newValue'] == 'wontfix' or
                    transaction['newValue'] == 'resolved')):
                timestamp = int(transaction['dateCreated'])
                self.is_closed = True
                return
        self.is_closed = False

    def resolved_between(self, start_date, end_date):
        """
        Returns True if the task was resolved between the two dates.
        """
        resolved_date = self.resolved_date()
        if resolved_date:
            return (
                resolved_date >= start_date and
                resolved_date < end_date
            )
        else:
            return False

    def resolved_date(self):
        """
        Returns date when task was resolved.
        Returns None if not resolved.
        """

        if self.cached_resolved_date:
            return self.cached_resolved_date

        for transaction in self.transactions:
            if (transaction['transactionType'] == 'status' and
                    transaction['newValue'] == 'resolved'):
                timestamp = int(transaction['dateCreated'])
                self.cached_resolved_date = datetime.fromtimestamp(timestamp)
                self.is_resolved = True
                return self.cached_resolved_date
        self.is_resolved = False
        return None

    def start_date(self):
        """
        Returns date when task was put into In Progress column.
        If task was never moved to In Progress, returns None.
        """
        if self.cached_start_date:
            return self.cached_start_date

        for transaction in self.transactions:
            if transaction['transactionType'] == 'projectcolumn':
                columns = self.get_transaction_columns(transaction)
                if columns['newValue'] == CONFIG['in_progress_column_value']:
                    timestamp = int(transaction['dateCreated'])
                    self.cached_start_date = datetime.fromtimestamp(timestamp)
                    return self.cached_start_date
        return None

    def cycle_time(self):
        return self.resolved_date() - self.start_date()

    def lead_time(self):
        return self.resolved_date() - self.created_date()

    def created_date(self):
        """
        Returns date when task was created.
        """
        if self.cached_created_date:
            return self.cached_created_date

        transaction = self.transactions[-1]
        timestamp = int(transaction['dateCreated'])
        self.cached_created_date = datetime.fromtimestamp(timestamp)
        return self.cached_created_date


    def column_at(self, date):
        """
        Returns the value of the column in which the task was at the given date.
        If the date is 'now', returns the column where the task is currently.
        """
        current_column = 0  # Board's initial column.
        # Transactions are sorted by timestamp, newest to oldest.
        # So they need to be reversed.
        for transaction in reversed(self.transactions):
            if transaction['transactionType'] == 'projectcolumn':
                timestamp = int(transaction['dateCreated'])
                transaction_date = datetime.fromtimestamp(timestamp)
                if date == 'now' or transaction_date <= date:
                    columns = self.get_transaction_columns(transaction)
                    current_column = columns['newValue']
                else:
                    # First column change after the given date.
                    # This means the current_column is the requested value.
                    break
        return current_column

    def steps_between(self, start_date, end_date):
        """
        Returns the number of column changes that a task has suffered,
        regardless if they are forwards or backwards. Only specified
        workboard columns do count. If a task jumps various steps in one
        transaction, they are counted as separate.
        """
        steps = 0
        for transaction in self.transactions:
            if transaction['transactionType'] == 'projectcolumn':
                columns = self.get_transaction_columns(transaction)
                steps += abs(columns['newValue'] - columns['oldValue'])
        return steps

    def get_transaction_columns(self, transaction):
        """
        Assumes the transaction is of type 'projectcolumn'.
        Returns the transaction's normalized old and new column values.
        """
        column_values = {}
        for kind in ['oldValue', 'newValue']:
            column_phids = transaction[kind]['columnPHIDs']
            # Phabricator api is crazy and returns different data types
            # for the same field. Sometimes list, sometimes dict.
            if type(column_phids) == list and len(column_phids) > 0:
                column_phid = column_phids[0]
            elif type(column_phids) == dict and len(column_phids) > 0:
                column_phid = column_phids.values()[0]
            else:
                column_values[kind] = 0 # Outside of workboard.
                continue
            # Translate Phabricator column phab-ids into column values.
            if column_phid in CONFIG['column_names']:
                column_name = CONFIG['column_names'][column_phid]
                column_values[kind] = CONFIG['column_values'][column_name]
            else:
                column_values[kind] = 0 # Outside of workboard.
        return column_values


def calculate_tasks_resolved(tasks, args):
    """
    Returns the number of tasks that have been
    marked as resolved between args.start_date and args.end_date.
    """
    tasks_resolved = 0
    for task in tasks:
        if task.resolved_between(args.start_date, args.end_date):
            tasks_resolved += 1
    return tasks_resolved

def calculate_timedeltas_average(timedeltas):
    if len(timedeltas) == 0:
        return None
    seconds_list = [t.total_seconds() for t in timedeltas]
    average_seconds = sum(seconds_list) / float(len(seconds_list))
    average_timedelta = timedelta(seconds=average_seconds)
    average_timedelta -= timedelta(microseconds=average_timedelta.microseconds)
    return average_timedelta

def print_cfd_table(tasks, args):
    """
    Prints CFD (Cumulative Flow Diagram) table
    """

    column_headers = '\t'.join(c['name'].ljust(15) for c in CONFIG['columns'][1:])
    column_headers += '\tDone'
    print('Date\t\t' + column_headers)
    days_in_range = (args.end_date - args.start_date).days
    current_day = args.start_date
    done_column = get_done_column(tasks, args)
    for i in range(days_in_range):
        column_counts = joined_column_counts_for_day(current_day, tasks, done_column, args.start_date)
        print(current_day.strftime(DATE_FORMAT) + '\t' + column_counts)
        current_day += timedelta(days=1)

def get_done_column(tasks, args):
    days_in_range = (args.end_date - args.start_date).days
    done_column = [0] * days_in_range
    for task in tasks:
        if task.is_resolved and task.resolved_between(args.start_date, args.end_date):
            start_fill_index = (task.resolved_date() - args.start_date).days
            for i in range(start_fill_index, days_in_range):
                done_column[i] += 1
    return done_column

def joined_column_counts_for_day(day, tasks, done_column, start_date):
    return '\t'.join(str(c).ljust(15) for c in column_counts_for_day(day, tasks, done_column, start_date))

def show_cfd(tasks, args):
    """
    Render cumulative flow diagram
    """
    import pylab as plt
    import matplotlib.patches as mpatches

    days_in_range = (args.end_date - args.start_date).days
    dates = [(args.start_date + timedelta(days=d)) for d in range(days_in_range)]
    column_count = len(CONFIG['columns'])
    Y = [[] for _ in range(column_count)]
    current_day = args.start_date
    done_column = get_done_column(tasks, args)
    for day_index in range(days_in_range):
        column_counts = column_counts_for_day(current_day, tasks, done_column, args.start_date)
        for column_index, column_count in enumerate(column_counts):
            Y[column_index].append(column_count)
        current_day += timedelta(days=1)

    polys = plt.stackplot(dates, *Y, baseline="zero")

    column_names = [c['name'] for c in CONFIG['columns'][1:]]
    column_names.append('Done')
    legend_proxies = []
    for i, poly in enumerate(polys):
        legend_proxies.append(mpatches.Patch(color=poly.get_facecolor()[0], label=column_names[i]))
    plt.legend(handles=legend_proxies)
    plt.title("Cumulative Flow %s to %s" % (args.start_date.strftime(DATE_FORMAT), args.end_date.strftime(DATE_FORMAT)))
    plt.axis('tight')
    plt.show()

def column_counts_for_day(day, tasks, done_column, start_date):
    column_counts = [0] * (len(CONFIG['columns']) - 1)
    for task in tasks:
        task_is_invalid = task.resolved_date() == None and task.is_closed
        if task_is_invalid:
            continue
        if task.resolved_date() and task.resolved_date().date() <= day.date():
            continue
        column_value = task.column_at(day)
        if column_value >= 1:
            column_counts[column_value - 1] += 1
    day_index = (day - start_date).days
    column_counts.append(done_column[day_index])
    return column_counts

def print_results(tasks, args):
    cycle_times = []
    lead_times = []

    # Calculate the metrics
    tasks_resolved = calculate_tasks_resolved(tasks, args)
    days_in_range = (args.end_date - args.start_date).days
    days_per_week = 7
    throughput = (tasks_resolved / float(days_in_range)) * days_per_week

    # Print task stats
    print('Date: %s - %s' % (args.start_date.strftime(DATE_FORMAT), args.end_date.strftime(DATE_FORMAT)))
    print('Completed Tasks (%d):' % tasks_resolved)
    print('ID\tCreated Date\t\tStart Date\t\tEnd Date\t\tCycle Time\t\tLead Time\t\tTask')
    for task in tasks:
        if task.resolved_between(args.start_date, args.end_date):
            created_date = str(task.created_date()).ljust(20)
            start_date = str(task.start_date()).ljust(20)
            if task.start_date():
                cycle_times.append(task.cycle_time())
                cycle_time = str(cycle_times[-1]).ljust(20)
            else:
                cycle_time = 'None'.ljust(20)
            lead_times.append(task.lead_time())
            lead_time = str(lead_times[-1]).ljust(20)
            print "%s\t%s\t%s\t%s\t%s\t%s\t%s" % (task.id, created_date, start_date, task.resolved_date(), cycle_time, lead_time, task.name)

    average_cycle_time = calculate_timedeltas_average(cycle_times)
    average_lead_time = calculate_timedeltas_average(lead_times)

    print('')
    print_cfd_table(tasks, args)

    # Print aggregate stats
    print('')
    print('Average cycle time: %s' % average_cycle_time)
    print('Average lead time: %s' % average_lead_time)
    print('Tasks completed per week (throughput): %.1f' % throughput)
    print('Note: average cycle time ignores tasks without a start date')

    show_cfd(tasks, args)

def generate_html(tasks, args):
    generator = HtmlGenerator(tasks, args)
    html = generator.html()

    text_file = open(args.html_file, "w")
    text_file.write(html)
    text_file.close()

    if args.open:
        os.system("open " + args.html_file)

class HtmlGenerator(object):
    def __init__(self, tasks, args):
        self.tasks = tasks
        self.args = args
        self.cycle_times = [] # TODO handle resetting these if reusing html method
        self.lead_times = []
        self.tasks_resolved = 0

    def html(self):
        self.tasks_resolved = calculate_tasks_resolved(tasks, args)

        body = """
            <div class="container" style="width: 100%%; margin: 15px;">
                <h2>Completed tasks (%d)</h2>
                <p>%s to %s</p>
                %s
                <h2>Statistics</h2>
                %s
                <h2>Cumulative Flow Diagram</h2>
                <div id="chart" style="width: 90%%;margin: auto;" />
                %s
            </div>
        """ % (self.tasks_resolved,
            args.start_date.strftime(DATE_FORMAT),
            args.end_date.strftime(DATE_FORMAT),
            self.get_table(),
            self.get_aggregate_stats(),
            self.get_chart_script())

        html = """
            <html>
              <head>
                <link rel="stylesheet" href="css/blueprint/screen.css" type="text/css" media="screen, projection">
                <link rel="stylesheet" href="css/blueprint/print.css" type="text/css" media="print">
                <!--[if lt IE 8]>
                  <link rel="stylesheet" href="css/blueprint/ie.css" type="text/css" media="screen, projection">
                <![endif]-->

                <link href="css/c3.min.css" rel="stylesheet" type="text/css">
                <script type="text/javascript" src="http://d3js.org/d3.v3.js"></script>
                <script type="text/javascript" src="c3.min.js"></script>
              </head>
              <body>%s</body>
            </html>
            """ % body
        return html

    def get_table(self):
        table_rows = ''

        for task in self.tasks:
            if task.resolved_between(args.start_date, args.end_date):
                created_date = str(task.created_date()).ljust(20)
                start_date = str(task.start_date()).ljust(20)
                if task.start_date():
                    self.cycle_times.append(task.cycle_time())
                    cycle_time = str(self.cycle_times[-1]).ljust(20)
                else:
                    cycle_time = 'None'.ljust(20)
                self.lead_times.append(task.lead_time())
                lead_time = str(self.lead_times[-1]).ljust(20)
                task_url = '%sT%s' % (CONFIG['phab_base_url'], task.id)
                task_id_link = '<a href=%s>T%s</a>' % (task_url, task.id)
                table_rows += """
                    <tr>
            			<td>%s</td>
            			<td>%s</td>
            			<td>%s</td>
            			<td>%s</td>
            			<td>%s</td>
            			<td>%s</td>
            			<td>%s</td>
            		</tr>
                """ % (task_id_link, created_date, start_date, task.resolved_date(), cycle_time, lead_time, task.name)
        table = """
        	<table>
        		<tr>
        			<th>ID</th>
        			<th>Created Date</th>
        			<th>Start Date</th>
        			<th>Completed Date</th>
        			<th>Cycle Time</th>
        			<th>Lead Time</th>
        			<th>Title</th>
                </tr>
        		%s
            </table>
        """ % table_rows
        return table

    def get_chart_script(self):
        column_names = [c['name'] for c in CONFIG['columns'][1:]]
        column_names.append('Done')
        column_count = len(column_names)

        dates = []
        columns = [[] for _ in range(column_count)]
        done_column = get_done_column(self.tasks, self.args)
        days_in_range = (self.args.end_date - self.args.start_date).days
        current_day = self.args.start_date
        for day_index in range(days_in_range):
            column_counts = column_counts_for_day(current_day, tasks, done_column, args.start_date)
            for column_index, column_count in enumerate(column_counts):
                columns[column_index].append(column_count)
            dates.append(current_day.strftime(DATE_FORMAT))
            current_day += timedelta(days=1)

        # prepend column name to each column of data
        columns = [[column_names[i]] + column for i, column in enumerate(columns)]

        x_axis = ['x'] + dates
        columns = [x_axis] + columns

        types = dict((column_name, 'area') for column_name in column_names)
        script = """
            <script type="text/javascript">
            var chart = c3.generate({
                data: {
                    x: 'x',
                    columns: %s,
                    types: %s,
                    groups: [%s],
                    order: null
                },
                axis: {
                  x: {
                    type: 'timeseries',
                    tick: {
                      format: '%%Y-%%m-%%d'
                    }
                  }
                }
            });
            </script>
        """ % (json.dumps(columns), json.dumps(types), json.dumps(column_names))
        return script

    def get_aggregate_stats(self):
        average_cycle_time = calculate_timedeltas_average(self.cycle_times)
        average_lead_time = calculate_timedeltas_average(self.lead_times)
        days_in_range = (self.args.end_date - self.args.start_date).days
        days_per_week = 7
        throughput = (self.tasks_resolved / float(days_in_range)) * days_per_week
        return """
            <table style="width: 700px">
                <tr>
                    <th>Statistic</th>
                    <th>Value</th>
                    <th>Description</th>
                </tr>
                <tr>
                    <td>Cycle time</td>
                    <td>%s</td>
                    <td>Average time between when task was moved to In Progress column and when it was resolved</td>
                </tr>
                <tr>
                    <td>Lead time</td>
                    <td>%s</td>
                    <td>Average time between when task was created and when it was resolved</td>
                </tr>
                <tr>
                    <td>Throughput</td>
                    <td>%.1f</td>
                    <td>Average number of tasks completed per week</td>
                </tr>
            </table>
            """ % (average_cycle_time, average_lead_time, throughput)

if __name__ == '__main__':
    args = parse_arguments()
    CONFIG = get_config(args)

    # Create the Phabricator API wrapper.
    phab = phabricator.Phabricator(timeout=500)

    # Get the tasks belonging to the given board.
    api_tasks = phab.maniphest.query(projectPHIDs=[CONFIG['workboard']])
    tasks = [
        Task(api_tasks[task_id]['id'], api_tasks[task_id]['title'])
        for task_id in api_tasks  # .values() not implemented
    ]

    # Decorate the tasks with their transactions.
    task_ids = [int(task.id) for task in tasks]
    transactions = phab.maniphest.gettasktransactions(ids=task_ids)
    for task in tasks:
        task.set_transactions(transactions[task.id])

    if args.html:
        generate_html(tasks, args)
    else:
        print_results(tasks, args)
